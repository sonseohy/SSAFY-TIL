{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Content License Agreement**\n","\n","<font color='red'><b>**WARNING**</b></font> : 본 자료는 삼성 청년 SW아카데미의 컨텐츠 자산으로, 보안서약서에 의거하여 어떠한 사유로도 임의로 복사, 촬영, 녹음, 복제, 보관, 전송하거나 허가 받지 않은 저장매체를 이용한 보관, 제3자에게 누설, 공개 또는 사용하는 등의 무단 사용 및 불법 배포 시 법적 조치를 받을 수 있습니다."],"metadata":{"id":"4O_zgP34Gt0K"}},{"cell_type":"markdown","source":["## **Objectives**\n","본 실습의 목표를 기입합니다. 아래 내용을 반드시 포함합니다.\n","1. 실습 개요\n","    - SERPAPI (실시간 검색 엔진)을 활용하여 최신 정보를 수집하는 기능 구현\n","    - 수집한 검색 결과를 DB에 저장\n","    - LangGraph를 사용하여 고도화된 RAG 파이프라인 구축\n","\n","2. 실습 진행 목적 및 배경\n","    - 목적: 실시간 검색과 이를 LangGraph로 구현함으로써 RAG 파이프라인을 고도화한다.\n","    - 배경: 실시간으로 데이터를 받아서 활용하는 것 역시 중요해지고 있으며 성능 개선을 위해 RAG의 고도화된 워크플로우를 구축하는 것이 중요해지고 있습니다.\n","\n","3. 실습 수행으로 얻어갈 수 있는 역량\n","    - SERPAPI 검색 엔진을 연동한 최신 정보 접근 및 활용 기술.\n","    - LangGraph를 활용한 RAG 워크플로우 설계 및 구현 능력.\n","    \n","\n","4. 실습 핵심 내용\n","    - SERPAPI 활용: 검색 결과를 JSON 형식으로 수집.\n","    - LangGraph를 활용한 워크플로우: 복잡한 다중 경로 RAG 워크플로우 설계 및 최적화."],"metadata":{"id":"wBMRC-8eG2Fh"}},{"cell_type":"markdown","source":["## **Prerequisites**\n","\n","\n","```\n","langchain == 0.3.12\n","langchain-chroma == 0.1.4\n","langchain-core == 0.3.25\n","langchain-openai == 0.2.12\n","langchain-text-splitters == 0.3.3\n","langchain-upstage == 0.4.0\n","getpass4 == 0.0.14.1\n","openai == 1.57.4\n","ragas == 0.2.8\n","langchain_community == 0.3.12\n","unstructured == 0.16.11\n","langgraph == 0.2.59\n","google-search-results == 2.4.2\n","```\n","\n"],"metadata":{"id":"EhMJqtdyG40p"}},{"cell_type":"code","source":["# 약 1분 소요\n","!pip install -qU openai langchain langchain-upstage langchain-chroma getpass4 langchain-community unstructured langgraph google-search-results"],"metadata":{"id":"sI8Xn9KJMVSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title set Upstage API key\n","import os\n","import getpass\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# Get the Upstage API key using getpass\n","try:\n","    if \"UPSTAGE_API_KEY\" not in os.environ or not os.environ[\"UPSTAGE_API_KEY\"]:\n","        os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n","\n","    print(\"API key has been set successfully.\")\n","\n","except:\n","    print(\"Something wrong with your API KEY. Check your API Console again.\")"],"metadata":{"id":"kBWBfXI93NCM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### SerpAPI API Key\n","- [SERPAPI](https://serpapi.com/) 회원 가입 후 API를 발급 받이 이용바랍니다."],"metadata":{"id":"iMWzyZSaQl3R"}},{"cell_type":"code","source":["from serpapi import GoogleSearch\n","\n","# SERPAPI KEY\n","if not os.getenv(\"SERPAPI_API_KEY\"):\n","    GoogleSearch.SERP_API_KEY = getpass.getpass(\"Enter your SERPAPI API key: \")\n","    os.environ[\"SERPAPI_API_KEY\"] = GoogleSearch.SERP_API_KEY"],"metadata":{"id":"YKirBWM35A6F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<font color='red'><b>**Caution**</b></font>\n","- SERPAPI는 한달에 100개의 검색을 무료로 사용할 수 있습니다. 지나치게 많이 활용할 경우, 사용 제한이 걸릴 수 있습니다."],"metadata":{"id":"L-FNT2lFHiT-"}},{"cell_type":"markdown","source":["## **Exercise Overview**\n","\n","실습 목차\n","- 실시간 검색 기능 RAG 시스템 구축 실습: 검색 엔진을 붙여 실시간 검색 기능을 활용하고, LangGraph을 사용하여 고도화된 형태의 RAG 파이프라인을 구축합니다.\n","    - 1) 실시간 검색 기능 활용\n","    - 2) LangGraph를 활용하여 고도화된 RAG 파이프라인 구축하기"],"metadata":{"id":"8-_D1uG2G67l"}},{"cell_type":"markdown","source":["## 1) 실시간 검색 기능 활용\n","\n","- SERPAPI 검색 엔진을 활용하여 실시간 검색을 수행합니다.\n","- 검색 엔진을 결합하여 질의응답을 수행합니다."],"metadata":{"id":"ZD1ZxAduG8ra"}},{"cell_type":"markdown","source":["#### 1-1) SERPAPI 검색 엔진을 활용하여 실시간 검색"],"metadata":{"id":"4ISK9W4fpm3A"}},{"cell_type":"code","source":["from serpapi import GoogleSearch\n","\n","# 3강에서 활용한 논문(openai-o1-system-card)과 관련된 내용을 검색합니다.\n","# TODO: 다음 질문들에 대한 검색 결과를 확인합니다.\n","questions = [\n","\"What distinguishes the o1 model’s reasoning capabilities from previous OpenAI models, and how does 'chain-of-thought' improve its performance?\",\n","'How does the o1 model perform in jailbreak evaluations compared to GPT-4o, and what measures have been implemented to resist adversarial prompts?',\n","'What are the key improvements in the o1 model regarding hallucinations and fairness compared to GPT-4o, and how were these measured?',\n","'What safety challenges arise from o1’s enhanced reasoning abilities, and how does OpenAI address the risks associated with chain-of-thought reasoning?',\n","'What were the findings from external red teaming efforts, particularly concerning the o1 model’s susceptibility to manipulation, persuasion, and scheming behaviors?'\n","]\n","\n","params = {\n","    \"engine\": \"google\",\n","    \"q\": questions[0],\n","    \"num\": \"4\"\n","}\n","search = GoogleSearch(params)"],"metadata":{"id":"VbHVfrGb4tP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["search_result = search.get_dict()"],"metadata":{"id":"_bEq-yQz7kZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 수집된 링크의 내용을 수집합니다! 파싱된 데이터를 검색시 활용되는 데이터로 활용할 수 있습니다.\n","from langchain.document_loaders import UnstructuredURLLoader\n","\n","# URL은 여러개 사용할 수 있습니다.\n","urls =\n","\n","loader = UnstructuredURLLoader(urls=urls)\n","data = loader.load()"],"metadata":{"id":"i-YZYB3_-VBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[0]"],"metadata":{"id":"ULDt-rdy-xwX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1-2) 검색 엔진을 결합하여 질의응답을 수행합니다."],"metadata":{"id":"rwNC8D8WqH7E"}},{"cell_type":"code","source":["from langchain_upstage import ChatUpstage\n","from langchain.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","\n","template = \"\"\"Answer the question based on context.\n","\n","Question: {question}\n","Context: {context}\n","Answer:\"\"\"\n","\n","llm = ChatUpstage()\n","prompt = ChatPromptTemplate.from_template(template)\n","parser = StrOutputParser()\n","\n","chain = (\n","    # chain을 실행했을 때, invoke를 통해 들어오는 데이터를 RunnablePassthrough method를 통해서 받음\n","    {},\n","    | prompt\n","    | llm\n","    | parser\n",")"],"metadata":{"id":"C7n4XNoACPSr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO: 다른 질문들에 대해서도 답변이 옳게 나왔는 지 확인해봅니다.\n","print(f\"질문: {questions[0]}\")\n","print(\"-\" * 20)\n","print(f\"답변:\\n{chain.invoke({'question': questions[0], 'context': data[0].page_content})}\")\n","print(f\"답변:\\n{chain.invoke({'question': questions[0], 'context': data[0].page_content}, encode='utf-8')}\")"],"metadata":{"id":"BjBxoz28Eob_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1-3) LangChain으로 SERPAPI 연동해서 사용하기"],"metadata":{"id":"yZM5l-HCIZKp"}},{"cell_type":"code","source":["# LangChain을 활용할 경우, Snippet만을 가져와서 사용합니다. (Snippet: 간략한 미리보기 텍스트)\n","from langchain_community.utilities import SerpAPIWrapper\n","\n","search = SerpAPIWrapper(params=params)\n","search.run(questions[0])"],"metadata":{"id":"SoQTgA5UIisb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 앞서 파싱한 결과물과 비교합니다.\n","search_result['organic_results'][0]['snippet']"],"metadata":{"id":"41_GSf2kJwWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2) LangGraph를 활용하여 고도화된 RAG 파이프라인 구축하기\n","\n","- [LangGraph](https://langchain-ai.github.io/langgraph/) 페이지를 참고하여 학습합니다.\n","\n","- Advanced RAG에서 배웠던 컨셉들을 활용하여 RAG의 구성 요소들의 성능 향상을 위한 기법들을 적용해봅니다.\n","\n","> Reference : https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag/"],"metadata":{"id":"VW6hZlyEFzG1"}},{"cell_type":"markdown","source":["![image](https://github.com/user-attachments/assets/532a17d2-bc80-46e6-9b24-05de5fb3894b)\n"],"metadata":{"id":"ObbCu73fGa_d"}},{"cell_type":"markdown","source":["1. 문서를 다운받고 DB 및 검색기를 생성합니다.\n","2. **Retrieve**: 질문에 관련된 문서를 검색합니다.\n","3. **Grade**: 검색된 문서가 적절한 지 판단합니다.\n","4. **Generate**: 적절할 경우, 질문과 함께 LLM에 입력하여 답변을 생성합니다.\n","5. **Re-Write**: 적절하지 않을 경우, 질문을 재정의합니다.\n","6. **Web Search**: 재정의된 질문을 기반으로 Web Search를 수행합니다.\n","7. **Generate**: 검색된 내용을 질문과 함께 LLM에 입력하여 답변을 생성합니다.\n","8. **그래프화**: 앞서 생성한 기능들을 그래프화 시켜 하나의 RAG 파이프라인으로 구현합니다.\n","\n","위 내용들을 자유롭게 Customizing 하여 나만의 LangGraph를 구현합니다."],"metadata":{"id":"ER5hhYUlGigM"}},{"cell_type":"markdown","source":["### 2-1) 문서를 다운받고 DB 및 검색기를 생성합니다."],"metadata":{"id":"S83rsDsNqiSH"}},{"cell_type":"code","source":["# 실습을 진행할 OpenAI o1 System Card 논문 다운로드\n","!wget -O openai-o1-system-card.pdf https://cdn.openai.com/o1-system-card-20241205.pdf"],"metadata":{"id":"KgepqrmPaM-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Document Parse로 다운로드 된 문서 불러오기\n","from langchain_upstage import UpstageDocumentParseLoader\n","\n","layzer = UpstageDocumentParseLoader(\n","    \"openai-o1-system-card.pdf\", # 불러올 파일\n","    output_format='html',  # 결과물 형태 : HTML\n","    coordinates= False) # 이미지 OCR 좌표계 가지고 오지 않기\n","\n","# 약 50초 소요\n","docs = layzer.load()"],"metadata":{"id":"Uerkb1LRaQa9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# chunk_size와 chunk_overlap에 따른 성능 비교해봤던 것 기억하시죠!?\n","# 여기서는 다른 값들에 따른 성능을 비교해봅시다!\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=200,\n","    chunk_overlap=50)\n","\n","splits = text_splitter.split_documents(docs)\n","\n","print(\"Splits:\", len(splits))"],"metadata":{"id":"bf5YWtSBapHh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","from langchain_chroma import Chroma\n","from langchain_upstage import UpstageEmbeddings\n","\n","# Chroma 활용하여 vectorstore 만들기\n","chroma_vectorstore = Chroma.from_documents(\n","     documents=splits, embedding=UpstageEmbeddings(model=\"embedding-query\")\n",")\n","\n","retriever = chroma_vectorstore.as_retriever(\n","    search_type= 'mmr', # default : similarity(유사도) / mmr 알고리즘\n","    search_kwargs={\"k\": 3} # 쿼리와 관련된 chunk를 3개 검색하기 (default : 4)\n",")"],"metadata":{"id":"RHqLtKZgbUgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions = [\n","'What distinguishes the o1 model’s reasoning capabilities from previous OpenAI models, and how does \"chain-of-thought\" improve its performance?',\n","'How does the o1 model perform in jailbreak evaluations compared to GPT-4o, and what measures have been implemented to resist adversarial prompts?',\n","'What are the key improvements in the o1 model regarding hallucinations and fairness compared to GPT-4o, and how were these measured?',\n","'What safety challenges arise from o1’s enhanced reasoning abilities, and how does OpenAI address the risks associated with chain-of-thought reasoning?',\n","'What were the findings from external red teaming efforts, particularly concerning the o1 model’s susceptibility to manipulation, persuasion, and scheming behaviors?'\n","]\n","\n","user_question = questions[0]"],"metadata":{"id":"nKduUcaidqIC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-2) **Retrieve**: 질문에 관련된 문서를 검색합니다.\n"],"metadata":{"id":"cpwwma6eGp7z"}},{"cell_type":"code","source":["docs = retriever.invoke(user_question)\n","docs = [doc.page_content for doc in docs]"],"metadata":{"id":"wOR4cUxOH7To"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-3) **Grade**: 검색된 문서가 적절한 지 판단합니다.\n"],"metadata":{"id":"j-FuMTUcH83n"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","from pydantic import BaseModel, Field\n","from langchain_upstage import ChatUpstage\n","from langchain.text_splitter import RecursiveCharacterTextSplitter"],"metadata":{"id":"f-mxBrzeGmxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## LangGraph에서 state별로 workflow를 실행하려면 다음과 같이 수행하면 됩니다.\n","\n","# Data model\n","class GradeDocuments(BaseModel):\n","    \"\"\" 검색된 문서가 질문과 관련이 있는 지 혹은 없는 지 확인합니다.Binary score for relevance check on retrieved documents.\"\"\"\n","    binary_score: str = Field(\n","        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n","    )\n","\n","\n","# LLM with function call\n","llm = ChatUpstage()\n","structured_llm_grader = llm.with_structured_output(GradeDocuments)\n","\n","# Prompt\n","system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n","    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n","    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n","\n","user = \"\"\"<<<Retrieved document>>>\n","{document}\n","\n","<<<User question>>>\n","{question}\n","\n","<<<Output Format>>>\n","`Score: <yes or no>`\n","\"\"\"\n","\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", user),\n","    ]\n",")\n","retrieval_grader = grade_prompt | structured_llm_grader"],"metadata":{"id":"bGQu-yq9bUqU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LLM Output Formatting 이슈로 에러가 발생할 수 있습니다. 어떻게 해결할 수 있을 지 생각해봅니다.\n","for doc in docs:\n","    score = retrieval_grader.invoke({\"question\": user_question, \"document\": doc})\n","    grade = score.binary_score\n","    print(grade)"],"metadata":{"id":"TqgLiRbmdmih"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-4) **Generate**: 적절할 경우, 질문과 함께 LLM에 입력하여 답변을 생성합니다.\n"],"metadata":{"id":"YZPr7X4hIVPz"}},{"cell_type":"code","source":["# yes가 2개 이상일 경우, 질문과 함께 LLM에 입력하여 답변을 획득합니다.\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# Prompt\n","system = \"\"\"\n","Answer the question based on context.\n","\"\"\"\n","user = \"\"\"\n","Question: {question}\n","Context: {context}\n","\n","<<<Output Format>>>\n","`Answer: <Answer based on the document.>`\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", user),\n","    ]\n",")\n","\n","# LLM & Chain\n","llm = ChatUpstage()\n","rag_chain = prompt | llm | StrOutputParser()"],"metadata":{"id":"TzAqNBjkilS1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate\n","generation = rag_chain.invoke({\"context\": \"\\n\\n\".join(docs), \"question\": user_question})\n","generation = generation.split(\":\")[1].strip() if \":\" in generation else generation.strip()\n","print(generation)"],"metadata":{"id":"MteigCmlj1pC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-5) **Re-Write**: 적절하지 않을 경우, 질문을 재정의합니다."],"metadata":{"id":"Mk0SL91Jnc1a"}},{"cell_type":"code","source":["### Question Re-writer\n","\n","# Prompt\n","system = \"\"\"\n","You a question re-writer that converts an input question to a better version that is optimized\n","for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n","\n","user = \"\"\"\n","Here is the initial question: {question}\n","Formulate an improved question.\n","\n","<<<Output Format>>>\n","`new question: <new question that is optimized for the web search>`\n","\"\"\"\n","\n","re_write_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", system),\n","        (\"human\", user),\n","    ]\n",")\n","llm = ChatUpstage()\n","question_rewriter = re_write_prompt | llm | StrOutputParser()"],"metadata":{"id":"RQi4uG2ulDOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_question"],"metadata":{"id":"kZwzyN_-Th7l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_question = question_rewriter.invoke({\"question\": user_question})\n","new_question = new_question.split(\":\")[1].strip() if \":\" in new_question else new_question.strip()\n","\n","# web_search에서 '\"'이 붙어있을 경우, 검색이 안되는 이슈가 존재합니다.\n","if new_question.startswith('\"'):\n","    new_question = new_question[1:]\n","if new_question.endswith('\"'):\n","    new_question = new_question[:-1]\n","\n","print(new_question)"],"metadata":{"id":"QoJRqRZZI-WD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-6) **Web Search**: 재정의된 질문을 기반으로 Web Search를 수행합니다."],"metadata":{"id":"JL-6hKd3I_CM"}},{"cell_type":"code","source":["from serpapi import GoogleSearch\n","from langchain.document_loaders import UnstructuredURLLoader\n","\n","params = {\n","    \"engine\": \"google\",\n","    \"q\": questions[0],\n","    \"num\": \"2\"\n","}\n","search = GoogleSearch(params)\n","search_result = search.get_dict()\n","\n","# URL은 여러개 사용할 수 있다.\n","urls = [result['link'] for result in search_result['organic_results']]\n","\n","loader = UnstructuredURLLoader(urls=urls)\n","data = loader.load()\n","\n","new_docs = [d.page_content for d in data]"],"metadata":{"id":"uapeu4_gKfLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_docs"],"metadata":{"id":"rHSoubrIXW91"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-7) **Generate**: 검색된 내용을 질문과 함께 LLM에 입력하여 답변을 생성합니다."],"metadata":{"id":"1byFC7ZbL9vn"}},{"cell_type":"code","source":["# Run\n","generation = rag_chain.invoke({\"context\": \"\\n\\n\".join(new_docs), \"question\": user_question})\n","generation = generation.split(\":\")[1].strip() if \":\" in generation else generation.strip()\n","print(generation)"],"metadata":{"id":"rQvGBUBjmV1k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-8) **그래프화**: 앞서 생성한 기능들을 그래프화 시켜 하나의 RAG 파이프라인으로 구현합니다.\n","\n","앞서 생성한 `retriever`, `retrieval_grader`, `rag_chain`, `question_rewriter`을 활용합니다."],"metadata":{"id":"4c6Tq2JXMMNR"}},{"cell_type":"code","source":["def retrieve(state):\n","    \"\"\" (2) Retrieve: 질문에 관련된 문서를 검색합니다. \"\"\"\n","    print(\"<<<RETRIEVE>>>\")\n","\n","    user_question = state[\"user_question\"]\n","    documents = retriever.get_relevant_documents(user_question)\n","    documents = [doc.page_content for doc in documents]\n","\n","    return {\"documents\": documents, \"user_question\": user_question}\n","\n","\n","def grade_documents(state):\n","    \"\"\" (3) Grade: 검색된 문서가 적절한 지 판단합니다. \"\"\"\n","    print(\"\\n<<<CHECK DOCUMENT RELEVANCE TO QUESTION>>>\")\n","\n","    user_question = state[\"user_question\"]\n","    docs = state[\"documents\"]\n","\n","    # 검색된 각 문서마다 통과 여부를 확인합니다.\n","    filtered_docs = []\n","    need_web_search = \"No\"\n","    for doc in docs:\n","        score = retrieval_grader.invoke(\n","            {\"question\": user_question, \"document\": doc}\n","        )\n","        grade = score.binary_score\n","\n","        if grade == \"yes\":\n","            print(\"---GRADE: DOCUMENT RELEVANT---\")\n","            filtered_docs.append(doc)\n","        else:\n","            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n","            need_web_search = \"Yes\"\n","\n","    return {\"documents\": filtered_docs, \"user_question\": user_question, \"web_search\": need_web_search}\n","\n","\n","def decide_to_generate(state):\n","    \"\"\" 검색을 종료하고 생성할 지 혹은 웹 검색을 수행할 지 결정합니다. \"\"\"\n","    print(\"\\n<<<ASSESS GRADED DOCUMENTS>>>\")\n","\n","    need_web_search = state[\"web_search\"]\n","\n","    # 검색이 필요할 경우 (1개라도 만족되지 않은 문서가 검색되었을 경우)\n","    if need_web_search == \"Yes\":\n","        print(\"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\")\n","        return \"query_rewrite\"\n","\n","    # 검색된 모든 문서가 만족되었을 경우\n","    else:\n","        print(\"---DECISION: GENERATE---\")\n","        return \"generate\"\n","\n","\n","def generate(state):\n","    \"\"\" (4) Generate: 적절할 경우, 질문과 함께 LLM에 입력하여 답변을 생성합니다. \"\"\"\n","    print(\"\\n<<<GENERATE>>>\")\n","\n","    user_question = state[\"user_question\"]\n","    documents = state[\"documents\"]\n","\n","    # RAG generation\n","    generation = rag_chain.invoke({\"context\": \"\\n\\n\".join(documents), \"question\": user_question})\n","    generation = generation.split(\":\")[1].strip() if \":\" in generation else generation.strip()\n","\n","    return {\"documents\": documents, \"user_question\": user_question, \"generation\": generation}\n","\n","\n","def query_rewrite(state):\n","    \"\"\" (5) Re-Write: 적절하지 않을 경우, 질문을 재정의합니다. \"\"\"\n","    print(\"\\n<<<TRANSFORM QUERY>>>\")\n","\n","    user_question = state[\"user_question\"]\n","    documents = state[\"documents\"]\n","\n","    # Re-write question\n","    web_question = question_rewriter.invoke({\"question\": user_question})\n","    web_question = web_question.split(\":\")[1].strip() if \":\" in web_question else web_question.strip()\n","\n","    # web_search에서 '\"'이 붙어있을 경우, 검색이 안되는 이슈가 존재합니다.\n","    if web_question.startswith('\"'):\n","        web_question = web_question[1:]\n","    if web_question.endswith('\"'):\n","        web_question = web_question[:-1]\n","\n","    return {\"documents\": documents, \"user_question\": web_question}\n","\n","def search_docs(state):\n","    \"\"\" (6) Web Search: 재정의된 질문을 기반으로 Web Search를 수행합니다. \"\"\"\n","\n","    print(\"\\n<<<SEARCH CONVERSATIONS>>>\")\n","    user_question = state[\"user_question\"]\n","    documents = state['documents']\n","\n","    params = {\n","        \"engine\": \"google\",\n","        \"q\": user_question,\n","        \"num\": \"2\"\n","    }\n","    search = GoogleSearch(params)\n","    search_result = search.get_dict()\n","\n","    # URL은 여러개 사용할 수 있다.\n","    urls = [result['link'] for result in search_result['organic_results']]\n","\n","    loader = UnstructuredURLLoader(urls=urls)\n","    data = loader.load()\n","\n","    new_documents = [d.page_content for d in data]\n","\n","    return {\"documents\": new_documents, \"user_question\": user_question}"],"metadata":{"id":"yROnAWJLMNqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LangGraph의 state 정의\n","from typing import List\n","from typing_extensions import TypedDict\n","\n","class GraphState(TypedDict):\n","    \"\"\" 그래프의 state로 들어갈 항목 정의 \"\"\"\n","    user_question: str\n","    documents: List[str]\n","    web_search: str\n","    generation: str"],"metadata":{"id":"An2IgRQhRZMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LangGraph 정의\n","from langgraph.graph import END, StateGraph, START\n","\n","workflow = StateGraph(GraphState)\n","\n","# Define the nodes\n","workflow.add_node(\"retrieve\", retrieve)  # retrieve\n","workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n","workflow.add_node(\"generate\", generate)  # generatae\n","workflow.add_node(\"search_docs\", search_docs)  # search_conversation\n","workflow.add_node(\"query_rewrite\", query_rewrite)  # query_rewrite\n","\n","# Build graph\n","workflow.add_edge(START, \"retrieve\")\n","workflow.add_edge(\"retrieve\", \"grade_documents\")\n","workflow.add_conditional_edges(\n","    \"grade_documents\",\n","    decide_to_generate,\n","    {\n","        \"query_rewrite\": \"query_rewrite\",\n","        \"generate\": \"generate\",\n","    },\n",")\n","workflow.add_edge(\"query_rewrite\", \"search_docs\")\n","workflow.add_edge(\"search_docs\", \"generate\")\n","workflow.add_edge(\"generate\", END)\n","\n","# Compile\n","app = workflow.compile()"],"metadata":{"id":"c5VcNuESN1NK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pprint import pprint\n","\n","# Run\n","# NOTE: Grade에서 포매팅 이슈로 에러가 발생할 수 있습니다. (재실행)\n","user_question = questions[1]\n","inputs = {\"user_question\": user_question}\n","for output in app.stream(inputs):\n","    for key, value in output.items():\n","        pprint(f\"Node '{key}'\")\n","    pprint(\"\\n---\\n\")\n","\n","# Final generation\n","pprint(value[\"generation\"])"],"metadata":{"id":"WxSIzQXlUg2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"답변:\\n\", value[\"generation\"])"],"metadata":{"id":"L9igbRsDVUGy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 🚀 실습 마무리\n","\n","이번 실습을 통해 실시간 검색 엔진을 활용한 최신 정보를 수진하는 기능과 LangGraph를 통한 RAG 파이프라인 고도화를 배웠습니다.\n","\n","LangGraph를 활용하는 방법은 위의 방법 말고도 다양한 방식들이 있을 수 있습니다. 본인만의 Custom된 Graph를 활용하여 본인만의 RAG 파이프라인을 만들어봅시다.\n","\n","이러한 기술들을 십분 활용하여 각자 설계한 서비스가 목표에 맞도록 구현될 수 있기를 바랍니다."],"metadata":{"id":"94WsrQRaSlh3"}},{"cell_type":"code","source":[],"metadata":{"id":"ewjJot2gTBNm"},"execution_count":null,"outputs":[]}]}